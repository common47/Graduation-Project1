{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809f54bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ime203\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ime203\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNLSTMClassifier(\n",
       "  (cnn): ShuffleNetV2(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (stage2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=58, bias=False)\n",
       "          (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
       "          (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
       "          (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
       "          (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
       "          (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (branch1): Sequential(\n",
       "          (0): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
       "          (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (4): ReLU(inplace=True)\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
       "          (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
       "          (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
       "          (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (branch1): Sequential()\n",
       "        (branch2): Sequential(\n",
       "          (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
       "          (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (7): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(464, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (fc): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from ultralytics import YOLO\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CNNLSTMClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_dim=128, lstm_layers=2, lstm_dropout=0.5):\n",
    "        super(CNNLSTMClassifier, self).__init__()\n",
    "        self.cnn = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "        num_ftrs = self.cnn.fc.in_features\n",
    "        self.cnn.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(num_ftrs, hidden_dim)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, lstm_layers, batch_first=True, dropout=lstm_dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 5:\n",
    "            batch_size, seq_length, c, h, w = x.size()\n",
    "            cnn_out = []\n",
    "            for t in range(seq_length):\n",
    "                cnn_out.append(self.cnn(x[:, t, :, :, :]))\n",
    "\n",
    "            cnn_out = torch.stack(cnn_out, dim=1)\n",
    "            lstm_out, _ = self.lstm(cnn_out)\n",
    "            lstm_out = lstm_out[:, -1, :]\n",
    "            out = self.fc(lstm_out)\n",
    "        elif len(x.shape) == 4:\n",
    "            cnn_out = self.cnn(x)\n",
    "            lstm_out, _ = self.lstm(cnn_out.unsqueeze(1))\n",
    "            lstm_out = lstm_out[:, -1, :]\n",
    "            out = self.fc(lstm_out)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported input shape\")\n",
    "\n",
    "        return out\n",
    "\n",
    "# CNN+LSTM 모델 초기화\n",
    "num_classes_cnnlstm = 4  # Adjust based on your dataset\n",
    "cnn_lstm_model = CNNLSTMClassifier(num_classes=num_classes_cnnlstm)\n",
    "cnn_lstm_model.load_state_dict(torch.load(r\"C:\\Users\\ime203\\Desktop\\Graduation\\cnn_lstm_model.pth\"))\n",
    "cnn_lstm_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6594879d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x416 4 Cars, 167.1ms\n",
      "Speed: 0.0ms preprocess, 167.1ms inference, 7.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 27.8ms\n",
      "Speed: 18.8ms preprocess, 27.8ms inference, 7.8ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 52.0ms\n",
      "Speed: 0.0ms preprocess, 52.0ms inference, 9.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 27.1ms\n",
      "Speed: 19.7ms preprocess, 27.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 33.7ms\n",
      "Speed: 8.1ms preprocess, 33.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 22.9ms\n",
      "Speed: 8.0ms preprocess, 22.9ms inference, 8.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 31.1ms\n",
      "Speed: 3.3ms preprocess, 31.1ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 28.1ms\n",
      "Speed: 14.0ms preprocess, 28.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 8 Cars, 41.5ms\n",
      "Speed: 10.0ms preprocess, 41.5ms inference, 9.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 48.2ms\n",
      "Speed: 0.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 1 Car, 33.4ms\n",
      "Speed: 1.1ms preprocess, 33.4ms inference, 7.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 29.6ms\n",
      "Speed: 8.0ms preprocess, 29.6ms inference, 10.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 28.3ms\n",
      "Speed: 8.0ms preprocess, 28.3ms inference, 7.8ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 51.3ms\n",
      "Speed: 15.7ms preprocess, 51.3ms inference, 8.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 33.2ms\n",
      "Speed: 9.2ms preprocess, 33.2ms inference, 7.3ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 30.4ms\n",
      "Speed: 9.1ms preprocess, 30.4ms inference, 3.5ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 37.3ms\n",
      "Speed: 15.6ms preprocess, 37.3ms inference, 15.6ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 32.3ms\n",
      "Speed: 9.9ms preprocess, 32.3ms inference, 8.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 42.2ms\n",
      "Speed: 10.2ms preprocess, 42.2ms inference, 8.3ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 36.5ms\n",
      "Speed: 9.6ms preprocess, 36.5ms inference, 18.2ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 36.3ms\n",
      "Speed: 15.2ms preprocess, 36.3ms inference, 8.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 40.5ms\n",
      "Speed: 0.0ms preprocess, 40.5ms inference, 11.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 21.4ms\n",
      "Speed: 8.0ms preprocess, 21.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 32.3ms\n",
      "Speed: 15.3ms preprocess, 32.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 25.3ms\n",
      "Speed: 8.0ms preprocess, 25.3ms inference, 8.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 23.9ms\n",
      "Speed: 17.3ms preprocess, 23.9ms inference, 7.3ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 27.0ms\n",
      "Speed: 11.7ms preprocess, 27.0ms inference, 7.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 42.2ms\n",
      "Speed: 8.0ms preprocess, 42.2ms inference, 7.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 28.6ms\n",
      "Speed: 18.0ms preprocess, 28.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 28.9ms\n",
      "Speed: 15.7ms preprocess, 28.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 20.8ms\n",
      "Speed: 8.0ms preprocess, 20.8ms inference, 15.6ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 30.4ms\n",
      "Speed: 15.7ms preprocess, 30.4ms inference, 8.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 19.9ms\n",
      "Speed: 8.0ms preprocess, 19.9ms inference, 15.7ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 25.5ms\n",
      "Speed: 17.7ms preprocess, 25.5ms inference, 7.5ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 33.9ms\n",
      "Speed: 4.2ms preprocess, 33.9ms inference, 11.3ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 18.7ms\n",
      "Speed: 8.0ms preprocess, 18.7ms inference, 15.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 32.2ms\n",
      "Speed: 0.0ms preprocess, 32.2ms inference, 16.6ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 30.9ms\n",
      "Speed: 15.9ms preprocess, 30.9ms inference, 2.2ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 32.2ms\n",
      "Speed: 17.2ms preprocess, 32.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 35.6ms\n",
      "Speed: 15.7ms preprocess, 35.6ms inference, 8.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 32.6ms\n",
      "Speed: 16.3ms preprocess, 32.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 18.6ms\n",
      "Speed: 15.0ms preprocess, 18.6ms inference, 19.9ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 17.2ms\n",
      "Speed: 16.6ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 16.7ms\n",
      "Speed: 5.1ms preprocess, 16.7ms inference, 22.4ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 29.7ms\n",
      "Speed: 7.8ms preprocess, 29.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 33.0ms\n",
      "Speed: 16.6ms preprocess, 33.0ms inference, 16.8ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 33.0ms\n",
      "Speed: 16.7ms preprocess, 33.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 32.5ms\n",
      "Speed: 0.0ms preprocess, 32.5ms inference, 17.4ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 49.7ms\n",
      "Speed: 0.0ms preprocess, 49.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 33.5ms\n",
      "Speed: 0.0ms preprocess, 33.5ms inference, 15.4ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 41.4ms\n",
      "Speed: 0.0ms preprocess, 41.4ms inference, 8.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 43.5ms\n",
      "Speed: 16.6ms preprocess, 43.5ms inference, 5.5ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 40.8ms\n",
      "Speed: 0.0ms preprocess, 40.8ms inference, 8.3ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 49.9ms\n",
      "Speed: 0.0ms preprocess, 49.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 45.9ms\n",
      "Speed: 0.0ms preprocess, 45.9ms inference, 6.8ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 49.9ms\n",
      "Speed: 0.0ms preprocess, 49.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 36.0ms\n",
      "Speed: 15.6ms preprocess, 36.0ms inference, 16.1ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 28.0ms\n",
      "Speed: 7.9ms preprocess, 28.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 36.6ms\n",
      "Speed: 15.7ms preprocess, 36.6ms inference, 16.2ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 33.7ms\n",
      "Speed: 16.4ms preprocess, 33.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 48.8ms\n",
      "Speed: 0.0ms preprocess, 48.8ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 16.3ms\n",
      "Speed: 16.3ms preprocess, 16.3ms inference, 16.2ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 32.3ms\n",
      "Speed: 0.0ms preprocess, 32.3ms inference, 16.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 32.3ms\n",
      "Speed: 1.1ms preprocess, 32.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 33.3ms\n",
      "Speed: 0.0ms preprocess, 33.3ms inference, 16.3ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 24.9ms\n",
      "Speed: 8.3ms preprocess, 24.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 33.0ms\n",
      "Speed: 15.1ms preprocess, 33.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 46.3ms\n",
      "Speed: 0.0ms preprocess, 46.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 32.2ms\n",
      "Speed: 2.1ms preprocess, 32.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 31.5ms\n",
      "Speed: 17.0ms preprocess, 31.5ms inference, 6.9ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 32.7ms\n",
      "Speed: 16.0ms preprocess, 32.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 29.8ms\n",
      "Speed: 16.6ms preprocess, 29.8ms inference, 3.2ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 43.4ms\n",
      "Speed: 0.0ms preprocess, 43.4ms inference, 6.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 32.3ms\n",
      "Speed: 0.0ms preprocess, 32.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 28.0ms\n",
      "Speed: 8.3ms preprocess, 28.0ms inference, 15.6ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 33.8ms\n",
      "Speed: 16.6ms preprocess, 33.8ms inference, 16.4ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 8 Cars, 36.1ms\n",
      "Speed: 8.2ms preprocess, 36.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 30.8ms\n",
      "Speed: 10.4ms preprocess, 30.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 33.7ms\n",
      "Speed: 17.0ms preprocess, 33.7ms inference, 16.3ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 32.7ms\n",
      "Speed: 16.4ms preprocess, 32.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 8 Cars, 32.9ms\n",
      "Speed: 0.0ms preprocess, 32.9ms inference, 16.4ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 28.7ms\n",
      "Speed: 0.0ms preprocess, 28.7ms inference, 20.3ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 30.1ms\n",
      "Speed: 7.5ms preprocess, 30.1ms inference, 10.9ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 29.0ms\n",
      "Speed: 18.5ms preprocess, 29.0ms inference, 7.1ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 32.2ms\n",
      "Speed: 7.0ms preprocess, 32.2ms inference, 8.2ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 29.4ms\n",
      "Speed: 14.1ms preprocess, 29.4ms inference, 15.6ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 42.1ms\n",
      "Speed: 7.0ms preprocess, 42.1ms inference, 8.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 8 Cars, 22.3ms\n",
      "Speed: 8.0ms preprocess, 22.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 8 Cars, 29.1ms\n",
      "Speed: 15.0ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 24.2ms\n",
      "Speed: 7.0ms preprocess, 24.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 34.9ms\n",
      "Speed: 2.9ms preprocess, 34.9ms inference, 9.1ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 35.0ms\n",
      "Speed: 0.0ms preprocess, 35.0ms inference, 16.1ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 29.1ms\n",
      "Speed: 20.1ms preprocess, 29.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 31.8ms\n",
      "Speed: 18.3ms preprocess, 31.8ms inference, 5.1ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 47.6ms\n",
      "Speed: 0.0ms preprocess, 47.6ms inference, 8.8ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 47.6ms\n",
      "Speed: 16.6ms preprocess, 47.6ms inference, 10.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 28.7ms\n",
      "Speed: 16.1ms preprocess, 28.7ms inference, 5.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 34.2ms\n",
      "Speed: 7.9ms preprocess, 34.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 40.6ms\n",
      "Speed: 0.0ms preprocess, 40.6ms inference, 8.3ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 32.1ms\n",
      "Speed: 16.5ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 32.9ms\n",
      "Speed: 0.0ms preprocess, 32.9ms inference, 15.3ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 49.2ms\n",
      "Speed: 0.0ms preprocess, 49.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 46.9ms\n",
      "Speed: 20.1ms preprocess, 46.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 39.1ms\n",
      "Speed: 0.0ms preprocess, 39.1ms inference, 7.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 32.3ms\n",
      "Speed: 17.0ms preprocess, 32.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 19.7ms\n",
      "Speed: 8.0ms preprocess, 19.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 47.7ms\n",
      "Speed: 4.2ms preprocess, 47.7ms inference, 7.8ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 32.4ms\n",
      "Speed: 0.0ms preprocess, 32.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 32.0ms\n",
      "Speed: 0.0ms preprocess, 32.0ms inference, 20.9ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 29.8ms\n",
      "Speed: 17.5ms preprocess, 29.8ms inference, 1.4ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 33.4ms\n",
      "Speed: 0.0ms preprocess, 33.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 32.1ms\n",
      "Speed: 17.9ms preprocess, 32.1ms inference, 8.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 43.4ms\n",
      "Speed: 0.0ms preprocess, 43.4ms inference, 5.5ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 32.1ms\n",
      "Speed: 17.0ms preprocess, 32.1ms inference, 8.7ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 36.3ms\n",
      "Speed: 0.9ms preprocess, 36.3ms inference, 7.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 33.7ms\n",
      "Speed: 16.4ms preprocess, 33.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 33.8ms\n",
      "Speed: 0.0ms preprocess, 33.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 24.6ms\n",
      "Speed: 8.0ms preprocess, 24.6ms inference, 14.3ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 17.3ms\n",
      "Speed: 14.1ms preprocess, 17.3ms inference, 17.5ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 50.6ms\n",
      "Speed: 15.5ms preprocess, 50.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 29.1ms\n",
      "Speed: 3.7ms preprocess, 29.1ms inference, 7.6ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 1 Car, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 16.8ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 16.3ms\n",
      "Speed: 16.2ms preprocess, 16.3ms inference, 16.5ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 34.1ms\n",
      "Speed: 0.0ms preprocess, 34.1ms inference, 17.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 18.2ms\n",
      "Speed: 15.0ms preprocess, 18.2ms inference, 16.6ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 17.7ms\n",
      "Speed: 15.8ms preprocess, 17.7ms inference, 15.7ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 29.0ms\n",
      "Speed: 19.7ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 33.4ms\n",
      "Speed: 8.1ms preprocess, 33.4ms inference, 16.2ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 31.8ms\n",
      "Speed: 16.7ms preprocess, 31.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 15.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 1 Car, 49.5ms\n",
      "Speed: 0.0ms preprocess, 49.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 49.5ms\n",
      "Speed: 0.0ms preprocess, 49.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 35.2ms\n",
      "Speed: 15.6ms preprocess, 35.2ms inference, 15.5ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 33.7ms\n",
      "Speed: 2.6ms preprocess, 33.7ms inference, 16.2ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 32.1ms\n",
      "Speed: 16.8ms preprocess, 32.1ms inference, 7.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 49.7ms\n",
      "Speed: 0.7ms preprocess, 49.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 4 Cars, 40.9ms\n",
      "Speed: 8.0ms preprocess, 40.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 32.9ms\n",
      "Speed: 0.0ms preprocess, 32.9ms inference, 17.4ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 32.8ms\n",
      "Speed: 1.1ms preprocess, 32.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 41.3ms\n",
      "Speed: 0.0ms preprocess, 41.3ms inference, 6.4ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 19.2ms\n",
      "Speed: 8.0ms preprocess, 19.2ms inference, 17.7ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 30.8ms\n",
      "Speed: 7.3ms preprocess, 30.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 2 Cars, 32.4ms\n",
      "Speed: 17.1ms preprocess, 32.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 5 Cars, 33.3ms\n",
      "Speed: 0.0ms preprocess, 33.3ms inference, 15.6ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 32.8ms\n",
      "Speed: 0.0ms preprocess, 32.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 33.6ms\n",
      "Speed: 0.0ms preprocess, 33.6ms inference, 16.2ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 3 Cars, 33.0ms\n",
      "Speed: 4.6ms preprocess, 33.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 7 Cars, 34.3ms\n",
      "Speed: 15.0ms preprocess, 34.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n",
      "\n",
      "0: 256x416 6 Cars, 32.4ms\n",
      "Speed: 16.9ms preprocess, 32.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 416)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from ultralytics import YOLO\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# OpenAI API 키 로드\n",
    "load_dotenv('.env')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# YOLO 모델 로드\n",
    "yolo_model = YOLO(r\"C:\\Users\\ime203\\Desktop\\Graduation\\runs\\detect\\Epochs80test\\weights\\best.pt\").to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# CNN+LSTM 모델 정의 및 로드\n",
    "class CNNLSTMClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_dim=128, lstm_layers=2, lstm_dropout=0.5):\n",
    "        super(CNNLSTMClassifier, self).__init__()\n",
    "        self.cnn = models.shufflenet_v2_x1_0(weights=models.ShuffleNet_V2_X1_0_Weights.DEFAULT)\n",
    "        num_ftrs = self.cnn.fc.in_features\n",
    "        self.cnn.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(num_ftrs, hidden_dim)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, lstm_layers, batch_first=True, dropout=lstm_dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 5:\n",
    "            batch_size, seq_length, c, h, w = x.size()\n",
    "            cnn_out = []\n",
    "            for t in range(seq_length):\n",
    "                cnn_out.append(self.cnn(x[:, t, :, :, :]))\n",
    "\n",
    "            cnn_out = torch.stack(cnn_out, dim=1)\n",
    "            lstm_out, _ = self.lstm(cnn_out)\n",
    "            lstm_out = lstm_out[:, -1, :]\n",
    "            out = self.fc(lstm_out)\n",
    "        elif len(x.shape) == 4:\n",
    "            cnn_out = self.cnn(x)\n",
    "            lstm_out, _ = self.lstm(cnn_out.unsqueeze(1))\n",
    "            lstm_out = lstm_out[:, -1, :]\n",
    "            out = self.fc(lstm_out)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported input shape\")\n",
    "\n",
    "        return out\n",
    "\n",
    "# 모델 인스턴스 및 로드된 가중치 설정\n",
    "num_classes = 4  # Adjust based on your dataset\n",
    "cnn_lstm_model = CNNLSTMClassifier(num_classes=num_classes)\n",
    "cnn_lstm_model.load_state_dict(torch.load(r\"C:\\Users\\ime203\\Desktop\\Graduation\\cnn_lstm_model.pth\"))\n",
    "cnn_lstm_model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.Lambda(lambda img: img.convert('RGB')),  # 이미지를 RGB로 변환\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 이미지 분류 함수\n",
    "def classify_image(image):\n",
    "    image = transform(image).unsqueeze(0)  # 배치 차원 추가\n",
    "    outputs = cnn_lstm_model(image)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    class_names = [\"Normal\", 1, 2, 3]  # Adjust based on your dataset\n",
    "    return class_names[preds.item()]\n",
    "\n",
    "# 객체 감지 함수\n",
    "def detect_objects(image):\n",
    "    results = yolo_model(image)\n",
    "    result_image = results[0].plot()  # 첫 번째 결과를 시각화\n",
    "    return Image.fromarray(result_image), results[0].boxes\n",
    "\n",
    "\n",
    "# OpenAI API를 사용한 이미지 분류 함수\n",
    "def classify_with_openai(api_key, img_path):\n",
    "    with open(img_path, \"rb\") as img_file:\n",
    "        base64_image = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "     payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Classify this image into: (1) Car-to-car accident, (2) Car-to-human accident, (3) Car-to-motorcycle, (4) Car-to-bicycle accident. Answer with the number. Image: data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    response_json = response.json()\n",
    "    \n",
    "    if response.status_code == 200 and 'choices' in response_json:\n",
    "        message_content = response_json['choices'][0]['message']['content']\n",
    "        if \"1\" in message_content:\n",
    "            return 1\n",
    "        elif \"2\" in message_content:\n",
    "            return 3\n",
    "        elif \"3\" in message_content:\n",
    "            return 2\n",
    "        elif \"4\" in message_content:\n",
    "            return 2\n",
    "        else:\n",
    "            return \"Normal\"  # No accident\n",
    "    else:\n",
    "        print(f\"Error in OpenAI API response: {response_json}\")\n",
    "        return \"Normal\"  # No accident\n",
    "\n",
    "# 이미지 감지 및 분류 함수\n",
    "def detect_and_classify(image):\n",
    "    try:\n",
    "        # 객체 감지\n",
    "        detected_image, boxes = detect_objects(image)\n",
    "        # 이미지 분류\n",
    "        classification_result = classify_image(image)\n",
    "        \n",
    "        # OpenAI API를 통한 이미지 분류\n",
    "        temp_image_path = \"temp_frame.jpg\"\n",
    "        image.save(temp_image_path)\n",
    "        openai_classification_result = classify_with_openai(openai_api_key, temp_image_path)\n",
    "        \n",
    "        # 앙상블을 위한 최종 분류 결과\n",
    "        final_classification_result = openai_classification_result if openai_classification_result != \"Normal\" else classification_result\n",
    "        \n",
    "        # 특정 조건에 따라 텍스트 추가 (예: 분류 결과가 \"1\" 또는 \"2\"일 경우)\n",
    "        if final_classification_result in [1, 2, 3]:\n",
    "            try:\n",
    "                draw = ImageDraw.Draw(detected_image)\n",
    "                font = ImageFont.truetype(\"arial.ttf\", 36)\n",
    "                \n",
    "                if final_classification_result == 1:\n",
    "                    text = \"Car-to-car Accident\"\n",
    "                elif final_classification_result == 3:\n",
    "                    text = \"Car-to-human Accident\"\n",
    "                elif final_classification_result == 2:\n",
    "                    text = \"Car-to-motorcycle/Bicycle Accident\"\n",
    "                \n",
    "                # 텍스트 크기를 계산\n",
    "                text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "                text_width = text_bbox[2] - text_bbox[0]\n",
    "                text_height = text_bbox[3] - text_bbox[1]\n",
    "                width, height = detected_image.size\n",
    "                x = (width - text_width) // 2\n",
    "                y = height // 10\n",
    "                draw.text((x, y), text, font=font, fill=(255, 0, 0))\n",
    "            except Exception as e:\n",
    "                print(f\"Error drawing text: {e}\")\n",
    "\n",
    "        return detected_image, final_classification_result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in detect_and_classify: {e}\")\n",
    "        return image, \"Error\"\n",
    "\n",
    "# 비디오 처리를 위한 함수\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        try:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil_image = Image.fromarray(frame_rgb)\n",
    "            detected_image, classification_result = detect_and_classify(pil_image)\n",
    "            frames.append(cv2.cvtColor(np.array(detected_image), cv2.COLOR_RGB2BGR))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame: {e}\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # 비디오 쓰기\n",
    "    if frames:\n",
    "        height, width, layers = frames[0].shape\n",
    "        size = (width, height)\n",
    "        output_path = 'output_video.mp4'\n",
    "        out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, size)\n",
    "\n",
    "        for frame in frames:\n",
    "            out.write(frame)\n",
    "        out.release()\n",
    "\n",
    "        return output_path\n",
    "    else:\n",
    "        return \"Error: No frames were processed.\"\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=process_video,\n",
    "    inputs=gr.Video(),\n",
    "    outputs=\"file\",  # 파일 다운로드 링크 제공\n",
    "    title=\"YOLO Object Detection and Image Classification in Videos\",\n",
    "    description=\"Upload a video to detect objects and classify images within the video.\"\n",
    ")\n",
    "\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a6728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
