{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d55907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ime203\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ime203\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from ultralytics import YOLO\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# YOLO 모델 로드\n",
    "yolo_model = YOLO(r\"C:\\Users\\ime203\\Desktop\\Graduation\\runs\\detect\\Epochs80test\\weights\\best.pt\")\n",
    "\n",
    "# ImageClassifier 모델 정의 및 로드\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x\n",
    "\n",
    "# 모델 인스턴스 및 로드된 가중치 설정\n",
    "num_classes = 3  # Adjust based on your dataset\n",
    "image_classifier = ImageClassifier(num_classes=num_classes)\n",
    "image_classifier.load_state_dict(torch.load(r\"C:\\Users\\ime203\\Desktop\\Graduation\\resnet18_image_classifier.pth\"))\n",
    "image_classifier.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.Lambda(lambda img: img.convert('RGB')),  # 이미지를 RGB로 변환\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 이미지 분류 함수\n",
    "def classify_image(image):\n",
    "    image = transform(image).unsqueeze(0)  # 배치 차원 추가\n",
    "    outputs = image_classifier(image)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    class_names = [\"0\", \"1\", \"2\"]  # Adjust based on your dataset\n",
    "    return class_names[preds.item()]\n",
    "\n",
    "# 객체 감지 함수\n",
    "def detect_objects(image):\n",
    "    results = yolo_model(image)\n",
    "    result_image = results[0].plot()  # 첫 번째 결과를 시각화\n",
    "    return Image.fromarray(result_image), results[0].boxes\n",
    "\n",
    "\n",
    "def detect_and_classify(image):\n",
    "    try:\n",
    "        # 객체 감지\n",
    "        detected_image, boxes = detect_objects(image)\n",
    "        # 이미지 분류\n",
    "        classification_result = classify_image(image)\n",
    "        \n",
    "        # 특정 조건에 따라 텍스트 추가 (예: 분류 결과가 \"1\" 또는 \"2\"일 경우)\n",
    "        if classification_result in [\"1\", \"2\"]:\n",
    "            try:\n",
    "                draw = ImageDraw.Draw(detected_image)\n",
    "                font = ImageFont.truetype(\"arial.ttf\", 36)\n",
    "                \n",
    "                if classification_result == \"1\":\n",
    "                    text = \"Level 1 Accident\"\n",
    "                elif classification_result == \"2\":\n",
    "                    text = \"Level 2 Accident\"\n",
    "                \n",
    "                bbox = draw.textbbox((0, 0), text, font=font)\n",
    "                textwidth, textheight = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
    "                width, height = detected_image.size\n",
    "                x = width // 2 - textwidth // 2\n",
    "                y = height // 10 - textheight // 2\n",
    "                draw.text((x, y), text, font=font, fill=(255, 0, 0))\n",
    "            except Exception as e:\n",
    "                print(f\"Error drawing text: {e}\")\n",
    "\n",
    "        return detected_image, classification_result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in detect_and_classify: {e}\")\n",
    "        return image, \"Error\"\n",
    "\n",
    "\n",
    "# 비디오 처리를 위한 함수\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        try:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil_image = Image.fromarray(frame_rgb)\n",
    "            detected_image, classification_result = detect_and_classify(pil_image)\n",
    "            frames.append(cv2.cvtColor(np.array(detected_image), cv2.COLOR_RGB2BGR))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame: {e}\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # 비디오 쓰기\n",
    "    if frames:\n",
    "        height, width, layers = frames[0].shape\n",
    "        size = (width, height)\n",
    "        output_path = 'output_video.mp4'\n",
    "        out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, size)\n",
    "\n",
    "        for frame in frames:\n",
    "            out.write(frame)\n",
    "        out.release()\n",
    "\n",
    "        return output_path\n",
    "    else:\n",
    "        return \"Error: No frames were processed.\"\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=process_video,\n",
    "    inputs=gr.Video(),\n",
    "    outputs=\"file\",  # 파일 다운로드 링크 제공\n",
    "    title=\"YOLO Object Detection and Image Classification in Videos\",\n",
    "    description=\"Upload a video to detect objects and classify images within the video.\"\n",
    ")\n",
    "\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dde275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
